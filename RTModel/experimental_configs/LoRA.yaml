task: 'LoRA'

reinit_n_layers: 0

input_dir: 'assets'

output_dir: 'results'

log_dir: 'logs'

model: 'bert'

seed: 42

dataset: 'amazon'

ignore_cache: False

debug: False

do_train: False

do_eval: False

distributed: False

save_model: True

# LoRA Parameter
r: 8

lora_alpha: 16

lora_dropout: 0.1