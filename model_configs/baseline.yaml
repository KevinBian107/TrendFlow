batch_size: 16

learning_rate: 0.0001

hidden_dim: 10

drop_rate: 0.9
#embed_dim is initial 10 but I change for fitting bert_model outputs size
embed_dim: 768 

adam_epsilon: 0.00000001

n_epochs: 10

max_len: 20

target_size: 18

early_stop_patience: 5